{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 b\n",
    "## 3 Nearest Neighbor Classification on Real Data\n",
    "### 3.1 Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "float64\n",
      "(8, 8)\n"
     ]
    }
   ],
   "source": [
    "#load dataset from sklearn\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.keys())\n",
    "\n",
    "data         = digits[\"data\"]\n",
    "images       = digits[\"images\"]\n",
    "target       = digits[\"target\"]\n",
    "target_names = digits[\"target_names\"]\n",
    "\n",
    "print(data.dtype)\n",
    "\n",
    "#check, what is the size of the images\n",
    "print(images[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the size of the images is 8x8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "img = images[13]\n",
    "\n",
    "assert (2 == len(img.shape)), \"img does not have a valid shape\"\n",
    "\n",
    "plt.figure()\n",
    "plt.gray()\n",
    "plt.imshow(img, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted some of the images and found out that for example the 13th image is a 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into a training and a test set\n",
    "from sklearn import model_selection\n",
    "\n",
    "X_all = data\n",
    "y_all = target\n",
    "\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    model_selection.train_test_split(digits.data, digits.target, \n",
    "                                    test_size = 0.4, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Distance function computation using loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define euclidian distance function using loops\n",
    "def dist_loop(training, test):\n",
    "    #test if the inputs are NxD, MxD matrices\n",
    "    assert (2 == len(np.shape(training))), \"training does not have a valid shape.\"\n",
    "    assert (2 == len(np.shape(test))), \"training does not have a valid shape.\"\n",
    "    assert (np.shape(test)[1] == np.shape(training)[1]), \"training and test do not have compatible shapes.\"\n",
    "    \n",
    "    #introduce MxN array for the output\n",
    "    N = np.shape(training)[0]\n",
    "    M = np.shape(test)[0]\n",
    "    D = np.shape(training)[1]\n",
    "    distances = np.zeros(shape=(N,M))\n",
    "    \n",
    "    #convert the input to numpy arrays\n",
    "    training = np.array(training)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    #compute the euclidian distance for every combination of one row from \n",
    "    #training and test each\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            distances[i][j] = np.linalg.norm(training[i]-test[j])\n",
    "            \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Distance function computation using vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_vec(training, test):\n",
    "    #test if the inputs are NxD, MxD matrices\n",
    "    assert (2 == len(np.shape(training))), \"training does not have a valid shape.\"\n",
    "    assert (2 == len(np.shape(test))), \"training does not have a valid shape.\"\n",
    "    assert (np.shape(test)[1] == np.shape(training)[1]), \"training and test do not have compatible shapes.\"   \n",
    "    \n",
    "    #convert trianing and test to numpy arrays\n",
    "    training = np.array(training)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    distances = np.linalg.norm(training[:, np.newaxis]-test, axis=2)\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.65685425  8.48528137 11.3137085 ]\n",
      " [ 2.82842712  5.65685425  8.48528137]]\n",
      "[[ 5.65685425  8.48528137 11.3137085 ]\n",
      " [ 2.82842712  5.65685425  8.48528137]]\n",
      "121 ms ± 11.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "16.7 s ± 824 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#test if the results of dist_loop and dist_vec are the same\n",
    "x = np.array([[1,2],[3,4]])\n",
    "y  = np.array([[5,6],[7,8],[9,10]])\n",
    "\n",
    "z = dist_vec(x,y)\n",
    "print(z)\n",
    "\n",
    "z = dist_loop(x,y)\n",
    "print(z)\n",
    "\n",
    "#test which method needs longer\n",
    "x = np.ones(shape=(1000,3))\n",
    "y = 2 * np.ones(shape=(1000,3))\n",
    "\n",
    "%timeit dist_vec(x,y)\n",
    "%timeit dist_loop(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both functions deliver the same results, but with N = M = 1000 the vectorized function is two orders of magnitude faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 k-Nearest-Neighbor-Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns a k-NN classifier\n",
    "def create_kNN(TS, k):\n",
    "    #the training dataset should be a numpy array of the form [[x_11,...,x_1D,y_1], [x21,...,x2D, y_2],...[x_N1,...,x_ND,y_N]]\n",
    "    \n",
    "    #define classifier\n",
    "    def classifier(x):\n",
    "        #training set\n",
    "        TS_X = TS.transpose()[:-1].transpose() \n",
    "        TS_Y = TS.transpose()[-1]\n",
    "        \n",
    "        #instance to be classified\n",
    "        X = x[:-1]\n",
    "        \n",
    "        #compute distances\n",
    "        dist = dist_vec(TS_X, np.array([X])).ravel()\n",
    "        \n",
    "        #determine the responses corresponding to the nearest feature vectors\n",
    "        Y_kNN = pd.Series(TS_Y[np.argsort(dist)[:k]])\n",
    "        tiebreak = TS_Y[np.argmin(dist)]\n",
    "        \n",
    "        #return the response which is most frequent\n",
    "        #in case of a tiebreak, the response of the nearest neighbor wins\n",
    "        if(len(Y_kNN.mode().to_numpy()) > 1):\n",
    "            return tiebreak\n",
    "        else:\n",
    "            return Y_kNN.mode().to_numpy()[0]\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter 3s and 9s from test set\n",
    "cond_test = np.logical_or(y_test==3, y_test==9)\n",
    "test = X_test[cond_test].transpose()\n",
    "test = np.append(test, [y_test[cond_test]], axis=0).transpose()\n",
    "\n",
    "#filter 3s and 9s from training set\n",
    "cond_train = np.logical_or(y_train==3, y_train==9)\n",
    "train = X_train[cond_train].transpose()\n",
    "train = np.append(train, [y_train[cond_train]], axis=0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k = 1\n",
      "error rate:  0.013888888888888888\n",
      "\n",
      "k = 3\n",
      "error rate:  0.006944444444444444\n",
      "\n",
      "k = 5\n",
      "error rate:  0.006944444444444444\n",
      "\n",
      "k = 9\n",
      "error rate:  0.006944444444444444\n",
      "\n",
      "k = 17\n",
      "error rate:  0.006944444444444444\n",
      "\n",
      "k = 33\n",
      "error rate:  0.020833333333333332\n"
     ]
    }
   ],
   "source": [
    "#function that computes the error rate for a given classifier cl and a test set test\n",
    "def compute_error_rate(cl, test):\n",
    "    wrong = 0\n",
    "    \n",
    "    for x in test:\n",
    "        if (x[-1] != cl(x)):\n",
    "            wrong += 1\n",
    "            \n",
    "    return wrong/len(test)\n",
    "\n",
    "#apply the function on the kNN-classifier trained with train and several values for k\n",
    "K = [1,3,5,9,17,33]\n",
    "for k in K:\n",
    "    print(\"\\nk =\", k)\n",
    "    #define classifier\n",
    "    cl = create_kNN(train, k)\n",
    "    error_rate = compute_error_rate(cl, test)\n",
    "    print(\"error rate: \", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as one would expect, the error rate is higher for very low (k=1) and very high (k=33) values. The optimal error rate can be obtained vor intermediate values of k (for example k= 9). From the results above, one cannot deduce, which value for k is optimal because we obtain the minimum error rate for several values for k (k=3,5,9,17). Maybe, a different test set could give us more information on that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
